<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[拷贝构造&深浅拷贝]]></title>
    <url>%2F2020%2F06%2F06%2F%E6%8B%B7%E8%B4%9D%E6%9E%84%E9%80%A0%26%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[构造函数是什么构造函数是一个特殊的成员函数，它的作用是初始化对象的成员属性(变量)； 构造函数的分类和调用规则根据参数分为：有参和无参构造函数，无参是默认的也可以自定义，有参只有自定义的； 根据功能分为：复制构造(拷贝构造(深拷贝和浅拷贝)、移动构造)和普通构造； 调用规则：需要注意的是，系统默认提供了三个类成员函数，构造函数、析构函数、拷贝函数，当定义了拷贝构造或者有参构造，那么默认的无参构造就不起作用了，析构函数是必调用的 1234567891011121314151617#include&lt;iostream&gt;using namespace std;class Preason&#123;public: Preason(int a);private: int m_age;&#125;;Preason::Preason(int a)&#123; m_age = a;&#125;int main()&#123; Preason p;//运行会报错，错误(活动) E0291 类 "Preason" 不存在默认构造函数&#125; 拷贝构造&amp;深浅拷贝首先要清楚的是，深浅拷贝是包含于拷贝构造这个概念的； 浅拷贝默认拷贝函数就是浅拷贝的一个实例，只能够进行值拷贝，不能拷贝内存空间； 123456789101112131415161718#include&lt;iostream&gt;using namespace std;class Preason&#123;public: Preason(int a);private: int m_age;&#125;;Preason::Preason(int a)&#123; m_age = a;&#125;int main()&#123; Preason p1(100); Preason p2 = p1;//默认拷贝&#125; 深拷贝上述情况只适用于类中没有指针变量的情况 123456789101112131415161718192021222324252627282930313233343536373839404142#define _CRT_SECURE_NO_WARNINGS#include&lt;iostream&gt;using namespace std;class Preason &#123;public: Preason(); Preason(char *name,int age); Preason(const Preason&amp; p); ~Preason();private: char* m_name; int m_age;&#125;;Preason::Preason()&#123; cout &lt;&lt; "无参构造" &lt;&lt; endl;&#125;Preason::Preason(char *name,int age):m_name(new char[strlen(name) + 1]),m_age( age) &#123; strcpy(m_name,name); cout &lt;&lt; "有参构造" &lt;&lt; endl;&#125;Preason::Preason(const Preason&amp; p)&#123; cout &lt;&lt; "拷贝构造" &lt;&lt; endl; m_name = p.m_name;//不注释这行和注释掉这行的差别看下面截图 m_age = p.m_age;&#125;Preason::~Preason()&#123; if(m_name) delete m_name; m_name = NULL; cout &lt;&lt; "析构函数" &lt;&lt; endl;&#125;int main(int argc,char *argv[])&#123; char n[] = "dfs"; Preason p1(n,100); Preason p2(p1);&#125; 仔细看下面的两个截图 在main函数中实例化了两个对象，分别用有参和拷贝初始化，正常情况应该有两个析构函数调用，而第二个图在调用析构函数释放p2对象时，触发断点，这是为何呢？ 这是发生断点的程序的监视图，可以看到两个对象的m_name指向了同一块内存，p1在调用析构函数时已经释放掉了0x017d6080这块内存,而当p2调用析构时要释放的还是这块内存，这就产生了指针悬挂问题，触发断点 123456789//深拷贝Preason::Preason(const Preason&amp; p)&#123; cout &lt;&lt; "拷贝构造" &lt;&lt; endl; //m_name = p.m_name; m_name = new char[strlen(p.m_name)+1]; strcpy(m_name,p.m_name); m_age = p.m_age;&#125; 深浅拷贝的示意图 使用场景拷贝函数使用场景以及匿名对象的概念12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include&lt;iostream&gt;using namespace std;class Preason &#123;public: Preason(); Preason(int age); Preason(const Preason&amp; p); ~Preason(); int getage();private: int m_age;&#125;;Preason::Preason()&#123; cout &lt;&lt; "无参构造" &lt;&lt; endl;&#125;Preason::Preason(int age) &#123; m_age = age; cout &lt;&lt; "有参构造" &lt;&lt; endl;&#125;Preason::Preason(const Preason&amp; p)&#123; cout &lt;&lt; "拷贝构造" &lt;&lt; endl; m_age = p.m_age;&#125;Preason::~Preason()&#123; cout &lt;&lt; "析构函数" &lt;&lt; endl;&#125;int Preason::getage()&#123; return m_age;&#125;//1.使用已存在的对象初始化新的对象void test_a()&#123; Preason p1(100); Preason p2(p1);&#125;//2.对象以值传递的方式给函数参数传值void test_1(Preason p)&#123;&#125;void test_b()&#123; Preason p1(100); test_1(p1); //Preason p=Preason (p1)调用了一次拷贝&#125;//3.对象以值传递的方式从函数返回 Preason test_2()&#123; Preason p1(100); cout &lt;&lt; p1.getage()&lt;&lt;endl; return p1;&#125;void test_c()&#123; Preason p = test_2(); cout &lt;&lt; p.getage()&lt;&lt;endl;&#125;int main()&#123; //构造初始化 //Preason p1(10);//隐式调用 //Preason p2 = Preason(100);//显示调用 //拷贝初始化 //Preason p1(100); //Preason p2 = p1; //Preason(20);//匿名对象，编译器在本行代码执行完，会自动释放这个对象 //cout &lt;&lt; "匿名对象会马上调用析构"&lt;&lt;endl;&#125; 对象以值传递的方式给函数参数传值 对象以值传递的方式从函数返回 总结1.拷贝构造函数其实是一个构造函数的重载 2.拷贝构造函数的参数只有一个，且必须传引用 3.浅拷贝只是对指针的拷贝，拷贝后两个指针指向同一个内存空间，深拷贝不但对指针进行拷贝，而且对指针指向的内容进行拷贝，经深拷贝后的指针是指向两个不同地址的指针]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>构造函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker搭建hadoop集群]]></title>
    <url>%2F2020%2F04%2F21%2Fdocker%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Docker安装：（windows下限制较多，docker的linux模式与VM的虚拟服务会冲突，每次使用需要重新开关服务，重启电脑，所以是在windows上的虚拟主机（VM）中实现，此教程适合使用过linux系统的人员）docker安装：https://www.runoob.com/docker/centos-docker-install.html 不同的系统只要安装好docker后，docker的操作都是一样的 docker的基本使用启动docker服务 service docker start docker刚安装好是没有镜像的，我用的ubuntu来搭建hadoop集群，也可以用其他linux发行版 docker pull ubuntu //拉取也就是在docker中下载ubuntu镜像,默认是最新的等待下载完成 docker images //查看镜像，可以看到刚拉取的ubuntu镜像 123root@linux:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest 72300a873c2c 8 weeks ago 64.2MB ok,因为hadoop集群的通信是需要局域网的，所以我们要创建hadoop的专用网络，用桥接模式 docker network create --driver=bridge hadoop 创建好之后查看创建的网络 docker network ls 123456root@liunx:~# docker network lsNETWORK ID NAME DRIVER SCOPEa520acd0f5eb bridge bridge local62cb2d841382 hadoop bridge localb7fef15ea068 host host localba108fc8779a none null local 然后用ubuntu镜像运行一个容器 docker run -it ubuntu /bin/bash //i和t分别是以交互模式和终端运行 12root@linux:~# docker run -it ubuntu /bin/bashroot@b434aef5bc5f:/# exit可以退出容器，ctrl+p+q切换shell到主机而不退出容器 docker ps //显示运行的容器 docker start 容器名/容器ID //运行一个存在的容器 stop是停止运行的容器 docker attach 容器名/容器ID //进入运行的容器 上面的命令之后会经常使用 ubuntu镜像的配置做完上面两部分之后，就是配置Ubuntu了，因为初始拉取的ubuntu镜像只有最基础的内核和文件系统，缺少网络工具,jdk,ssh,vim而这些是配置集群不可或缺的部分 在root@b434aef5bc5f:/# 1.换源,将下面的内容添加到/etc/apt/sources.list中123456789101112131415deb http://mirrors.aliyun.com/ubuntu/ xenial maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial maindeb http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates maindeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security maindeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe 2.使用apt update来更新源1234apt install net-toolsapt install inetutils-ping//安装ping工具,不能直接apt-get install ping，因为在inetutils里面apt install openjdk-8-jdkapt install vim 3.安装sshssh是一种应用层的安全远程登录协议，它会生成一对密匙，分别是私匙和公匙，详细解释可以去看ssh官方文档 apt-get install openssh-server apt-get install openssh-client 使用ssh-keygen -t rsa -P &#39;&#39;来创建无密码登录 123456789101112131415161718192021root@b434aef5bc5f:/# ssh-keygen -t rsa -P &apos;&apos; Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): /root/.ssh/id_rsa already exists.Overwrite (y/n)? yYour identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:p0UBShQiq/AxMBv+HxEku3a6WuwPkVu01E1HNck4kA8 root@cdbc600b933bThe key&apos;s randomart image is:+---[RSA 2048]----+|+ ..o++..+=o+o. ||.= oooo.oE.+ o. ||o.+. +.. .+ . ||.o.o= o . . ||. .* = S o || o B . + || * . . || o o || ..o.. |+----[SHA256]-----+ cat命令读出id_rsa.pub后以流的方式追加到authorized_keys中 cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys 启动ssh服务 123root@b434aef5bc5f:~# service ssh startStarting OpenBSD Secure Shell server sshd [ OK ] 172.17.0.2是容器b434aef5bc5f的IP地址 1234567891011121314151617root@b434aef5bc5f:~# ssh 172.17.0.2Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-kali2-amd64 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage This system has been minimized by removing packages and content that are not required on a system that users do not log into.To restore this content, you can run the &apos;unminimize&apos; command.The programs included with the Ubuntu system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted byapplicable law. 出现上述问题ssh -o StrictHostKeyChecking=no root@172.17.0.2 然后再次执行 成功！ 方便以后使用，追加service ssh start到.bashrc文件 vim /root/.bashrc 安装hadoop下载 wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz 解压 tar -zxvf hadoop-3.2.1.tar.gz -C /usr/local 修改 /etc/profile 文件，添加环境变量 vim /etc/profile 追加以下内容 123456789101112131415161718192021222324#javaexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH#hadoopexport HADOOP_HOME=/usr/local/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_YARN_HOME=$HADOOP_HOME export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HADOOP_CONF_DIR=$HADOOP_HOME export HADOOP_LIBEXEC_DIR=$HADOOP_HOME/libexec export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATHexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopexport HDFS_DATANODE_USER=rootexport HDFS_DATANODE_SECURE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport HDFS_NAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop 需要改为 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop否则运行hadoop命令需要找到路径并加./ 如果不嫌繁琐的话也可以不用改，最后几行代表hadoop是哪个用户，我用的root 运行source /etc/profile使其生效 在目录 /usr/local/hadoop/etc/hadoop 下 hadoop-env.sh 文件 123456export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root core-site.xml 文件 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://h01:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml文件 123456789101112131415&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml文件 1234567891011121314151617181920&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt; /usr/local/hadoop/etc/hadoop, /usr/local/hadoop/share/hadoop/common/*, /usr/local/hadoop/share/hadoop/common/lib/*, /usr/local/hadoop/share/hadoop/hdfs/*, /usr/local/hadoop/share/hadoop/hdfs/lib/*, /usr/local/hadoop/share/hadoop/mapreduce/*, /usr/local/hadoop/share/hadoop/mapreduce/lib/*, /usr/local/hadoop/share/hadoop/yarn/*, /usr/local/hadoop/share/hadoop/yarn/lib/* &lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml文件 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;h01&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; worker文件 123h00h01h02 hadoop终于搞完了 搭建集群上述步骤相当于在实体机搭建了一台分布式主机，但是我们需要的是hadoop集群，怎么能一台机器呢 所以我们要横向扩展，这也是hadoop集群的特性，易于扩展，也就是死命加机器(手动滑稽)。 在docker中就很方便了，将搞完hadoop的这个容器，也就相当于现实中，一台运行着的机器，直接将其复制无数相同的从节点机，当然我们只要两个从节点就够了，也就是第四步中worker文件的配置，h00为主节点，h01,h02为从节点。好了闲话不多说实操起来。 将容器打包成镜像，因为我们要扩展呀，必须得有镜像 docker commit -m &quot;haddop&quot; -a &quot;hadoop&quot; b434aef5bc5f myhadoop docker images查看，里面出现了myhadoop 扩展首先就是主节点，虽然之前的也可以用，但是我们要配置端口映射，不然无法在docker之外操作hadoop集群 docker run -it --network hadoop -h h01 --name &quot;h00&quot; -p 9870:9870 -p 8088:8088 -p 9000:9000 myhadoop /bin/bash //前两个端口是web端，9000是hdfs文件系统的端口映射 好了主节点配置好了，我们的hadoop集群有了大脑，然后增加两个从节点 docker run -it --network hadoop -h h01 --name &quot;h02&quot; myhadoop /bin/bash docker run -it --network hadoop -h h02 --name &quot;h02&quot; myhadoop /bin/bash 在客户机中创建docker.sh启动脚本里面添加下面内容，并且用chmod +x hadoop.sh使其可执行 12345service docker startdocker start h01docker start h02docker start h03docker attach h01 1234567root@linux:~# ./docker.sh h01h02h03root@h01:/# cat hadoop.sh ./usr/local/hadoop/sbin/start-all.shroot@h01:/# 启动集群在h01节点中先初始化hdfs，以后启动不用初始化，否则会报错 root@h01:/usr/local/hadoop/bin#./hadoop namenode -format 在/目录下创建hadoop集群启动脚本hadoop.sh，写入下面内容 ./usr/local/hadoop/sbin/start-all.sh 同docker启动脚本一样 每次启动h01运行source /etc/profile,执行命令就不用加./ 好了，hadoop完全分布式集群搭建到此结束]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
